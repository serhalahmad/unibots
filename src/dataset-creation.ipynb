{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "# rugby-balls: https://universe.roboflow.com/hotchickenpie/ruby-ball-detection/browse?queryText=&pageSize=50&startingIndex=0&browseQuery=true\n",
    "# mini-rugby balls: https://universe.roboflow.com/muhie-kk0uz/rugby-balls-zcnjx\n",
    "# ping-pong balls: https://universe.roboflow.com/pingpong-ojuhj/ping-pong-detection-0guzq/images/8SLEQwQoyRiRvY70azBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Ruby-Ball-Detection-3 to yolov11:: 100%|██████████| 31077/31077 [00:02<00:00, 13302.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Ruby-Ball-Detection-3 in yolov11:: 100%|██████████| 1304/1304 [00:00<00:00, 3064.93it/s]\n"
     ]
    }
   ],
   "source": [
    "rf = Roboflow(api_key=\"NIGjwRcd4EBYxngwiDkn\")\n",
    "project = rf.workspace(\"hotchickenpie\").project(\"ruby-ball-detection\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"yolov11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Ping-Pong-Detection-3 to yolov11:: 100%|██████████| 1461722/1461722 [01:07<00:00, 21693.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Ping-Pong-Detection-3 in yolov11:: 100%|██████████| 49688/49688 [00:19<00:00, 2581.22it/s]\n"
     ]
    }
   ],
   "source": [
    "rf = Roboflow(api_key=\"NIGjwRcd4EBYxngwiDkn\")\n",
    "project = rf.workspace(\"pingpong-ojuhj\").project(\"ping-pong-detection-0guzq\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"yolov11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.1.50-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from roboflow) (2024.8.30)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: cycler in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from roboflow) (1.4.7)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from roboflow) (3.9.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from roboflow) (1.26.3)\n",
      "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from roboflow) (10.2.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Collecting python-dotenv (from roboflow)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from roboflow) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from roboflow) (6.0.2)\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filetype (from roboflow)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from matplotlib->roboflow) (1.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from matplotlib->roboflow) (4.55.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from matplotlib->roboflow) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from matplotlib->roboflow) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marlo\\code\\qmul-societies\\.venv\\lib\\site-packages (from requests->roboflow) (3.4.0)\n",
      "Downloading roboflow-1.1.50-py3-none-any.whl (81 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Installing collected packages: filetype, python-dotenv, opencv-python-headless, idna, requests-toolbelt, roboflow\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 python-dotenv-1.0.1 requests-toolbelt-1.0.0 roboflow-1.1.50\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Downloading dataset 'ruby-ball-detection' version 3...\n",
      "INFO: Downloaded to 'C:\\Users\\Marlo\\code\\QMUL-Societies\\Electronics\\Unibots\\Computer_Vision\\dataset-creation\\Ruby-Ball-Detection-3'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Downloading dataset 'ping-pong-detection-0guzq' version 3...\n",
      "INFO: Downloaded to 'C:\\Users\\Marlo\\code\\QMUL-Societies\\Electronics\\Unibots\\Computer_Vision\\dataset-creation\\Ping-Pong-Detection-3'\n",
      "INFO: Merged data.yaml created at C:\\Users\\Marlo\\code\\QMUL-Societies\\Electronics\\Unibots\\Computer_Vision\\dataset-creation\\full-data\\data.yaml\n",
      "INFO: Copied 550 images and labels from 'C:\\Users\\Marlo\\code\\QMUL-Societies\\Electronics\\Unibots\\Computer_Vision\\dataset-creation\\Ruby-Ball-Detection-3' to split 'train'\n",
      "INFO: Copied 550 images and labels from 'C:\\Users\\Marlo\\code\\QMUL-Societies\\Electronics\\Unibots\\Computer_Vision\\dataset-creation\\Ping-Pong-Detection-3' to split 'train'\n",
      "INFO: Copied 50 images and labels from 'C:\\Users\\Marlo\\code\\QMUL-Societies\\Electronics\\Unibots\\Computer_Vision\\dataset-creation\\Ruby-Ball-Detection-3' to split 'valid'\n",
      "INFO: Copied 50 images and labels from 'C:\\Users\\Marlo\\code\\QMUL-Societies\\Electronics\\Unibots\\Computer_Vision\\dataset-creation\\Ping-Pong-Detection-3' to split 'valid'\n",
      "INFO: Copied 34 images and labels from 'C:\\Users\\Marlo\\code\\QMUL-Societies\\Electronics\\Unibots\\Computer_Vision\\dataset-creation\\Ruby-Ball-Detection-3' to split 'test'\n",
      "INFO: Copied 34 images and labels from 'C:\\Users\\Marlo\\code\\QMUL-Societies\\Electronics\\Unibots\\Computer_Vision\\dataset-creation\\Ping-Pong-Detection-3' to split 'test'\n",
      "INFO: Dataset combination complete.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "import logging\n",
    "import yaml\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# Parameters\n",
    "API_KEY = \"NIGjwRcd4EBYxngwiDkn\"\n",
    "\n",
    "# Define datasets with unique variable names\n",
    "datasets_info = [\n",
    "    {\n",
    "        \"workspace\": \"hotchickenpie\",\n",
    "        \"project\": \"ruby-ball-detection\",\n",
    "        \"version\": 3,\n",
    "        \"download_format\": \"yolov11\",\n",
    "        \"local_path\": r\"C:\\Users\\Marlo\\code\\QMUL-Societies\\Electronics\\Unibots\\Computer_Vision\\dataset-creation\\Ruby-Ball-Detection-3\"\n",
    "    },\n",
    "    {\n",
    "        \"workspace\": \"pingpong-ojuhj\",\n",
    "        \"project\": \"ping-pong-detection-0guzq\",\n",
    "        \"version\": 3,\n",
    "        \"download_format\": \"yolov11\",\n",
    "        \"local_path\": r\"C:\\Users\\Marlo\\code\\QMUL-Societies\\Electronics\\Unibots\\Computer_Vision\\dataset-creation\\Ping-Pong-Detection-3\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Initialize Roboflow\n",
    "rf = Roboflow(api_key=API_KEY)\n",
    "\n",
    "# Download each dataset\n",
    "for dataset in datasets_info:\n",
    "    project = rf.workspace(dataset[\"workspace\"]).project(dataset[\"project\"])\n",
    "    version = project.version(dataset[\"version\"])\n",
    "    logging.info(f\"Downloading dataset '{dataset['project']}' version {dataset['version']}...\")\n",
    "    version.download(dataset[\"download_format\"], location=dataset[\"local_path\"])\n",
    "    logging.info(f\"Downloaded to '{dataset['local_path']}'\")\n",
    "\n",
    "# Define source datasets paths\n",
    "SOURCE_DATASETS = [dataset[\"local_path\"] for dataset in datasets_info]\n",
    "\n",
    "# Define splits to ensure a total of 200 images per dataset\n",
    "# Example split: 160 train, 30 valid, 10 test\n",
    "SPLITS = {\n",
    "    \"train\": 550,\n",
    "    \"valid\": 50,\n",
    "    \"test\": 34\n",
    "}\n",
    "\n",
    "OUTPUT_DIR = r\"C:\\Users\\Marlo\\code\\QMUL-Societies\\Electronics\\Unibots\\Computer_Vision\\dataset-creation\\full-data\"\n",
    "OUTPUT_IMAGES_DIR = os.path.join(OUTPUT_DIR, \"images\")\n",
    "OUTPUT_LABELS_DIR = os.path.join(OUTPUT_DIR, \"labels\")\n",
    "OUTPUT_DATA_YAML = os.path.join(OUTPUT_DIR, \"data.yaml\")\n",
    "\n",
    "# Create output directories\n",
    "for split in SPLITS.keys():\n",
    "    os.makedirs(os.path.join(OUTPUT_IMAGES_DIR, split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(OUTPUT_LABELS_DIR, split), exist_ok=True)\n",
    "\n",
    "# Function to read data.yaml\n",
    "def read_data_yaml(dataset_path):\n",
    "    data_yaml_path = os.path.join(dataset_path, \"data.yaml\")\n",
    "    if not os.path.exists(data_yaml_path):\n",
    "        logging.error(f\"data.yaml not found in {dataset_path}\")\n",
    "        return None\n",
    "    with open(data_yaml_path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    return data\n",
    "\n",
    "# Function to merge class names\n",
    "def merge_classes(datasets_data):\n",
    "    merged_names = []\n",
    "    class_map = {}  # {dataset_idx: {original_class: merged_class_index}}\n",
    "    \n",
    "    for idx, data in enumerate(datasets_data):\n",
    "        if data is None:\n",
    "            continue  # Skip datasets without data.yaml\n",
    "        class_map[idx] = {}\n",
    "        for cls in data['names']:\n",
    "            if cls not in merged_names:\n",
    "                merged_names.append(cls)\n",
    "            class_map[idx][cls] = merged_names.index(cls)\n",
    "    \n",
    "    return merged_names, class_map\n",
    "\n",
    "# Read and merge data.yaml files\n",
    "datasets_data = [read_data_yaml(ds) for ds in SOURCE_DATASETS]\n",
    "merged_class_names, class_maps = merge_classes(datasets_data)\n",
    "merged_nc = len(merged_class_names)\n",
    "\n",
    "# Create merged data.yaml\n",
    "merged_data_yaml = {\n",
    "    'train': os.path.join(OUTPUT_IMAGES_DIR, 'train'),\n",
    "    'val': os.path.join(OUTPUT_IMAGES_DIR, 'valid'),\n",
    "    'test': os.path.join(OUTPUT_IMAGES_DIR, 'test'),\n",
    "    'nc': merged_nc,\n",
    "    'names': merged_class_names\n",
    "}\n",
    "\n",
    "with open(OUTPUT_DATA_YAML, 'w') as f:\n",
    "    yaml.dump(merged_data_yaml, f)\n",
    "\n",
    "logging.info(f\"Merged data.yaml created at {OUTPUT_DATA_YAML}\")\n",
    "\n",
    "def select_and_copy(dataset_idx, dataset_path, split, num_images, split_type):\n",
    "    split_path = os.path.join(dataset_path, split_type)\n",
    "    \n",
    "    if not os.path.exists(split_path):\n",
    "        logging.warning(f\"Split folder '{split_type}' does not exist in '{dataset_path}'. Skipping.\")\n",
    "        return\n",
    "\n",
    "    images_path = os.path.join(split_path, \"images\")\n",
    "    labels_path = os.path.join(split_path, \"labels\")\n",
    "\n",
    "    if not os.path.exists(images_path):\n",
    "        logging.warning(f\"'images' folder does not exist in '{split_path}'. Skipping.\")\n",
    "        return\n",
    "    if not os.path.exists(labels_path):\n",
    "        logging.warning(f\"'labels' folder does not exist in '{split_path}'. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Get all .jpg and .png images\n",
    "    image_files = glob.glob(os.path.join(images_path, \"*.jpg\")) + glob.glob(os.path.join(images_path, \"*.png\"))\n",
    "\n",
    "    if not image_files:\n",
    "        logging.warning(f\"No image files found in '{images_path}'.\")\n",
    "        return\n",
    "\n",
    "    # Sort image files to take the first N\n",
    "    image_files.sort()\n",
    "    selected_image_files = image_files[:num_images]\n",
    "\n",
    "    # Get corresponding label files\n",
    "    for img_file in selected_image_files:\n",
    "        basename = os.path.splitext(os.path.basename(img_file))[0]\n",
    "        src_label = os.path.join(labels_path, f\"{basename}.txt\")\n",
    "\n",
    "        if not os.path.exists(src_label):\n",
    "            logging.warning(f\"Label file '{src_label}' does not exist. Skipping image '{basename}'.\")\n",
    "            continue\n",
    "\n",
    "        # Destination paths\n",
    "        dest_image = os.path.join(OUTPUT_IMAGES_DIR, split, os.path.basename(img_file))\n",
    "        dest_label = os.path.join(OUTPUT_LABELS_DIR, split, os.path.basename(src_label))\n",
    "\n",
    "        # Copy image\n",
    "        shutil.copy2(img_file, dest_image)\n",
    "\n",
    "        # Read label, remap class if necessary\n",
    "        with open(src_label, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        remapped_lines = []\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                logging.warning(f\"Unexpected label format in '{src_label}'. Skipping line.\")\n",
    "                continue\n",
    "            original_cls, x_center, y_center, width, height = parts\n",
    "            try:\n",
    "                original_cls = int(original_cls)\n",
    "            except ValueError:\n",
    "                logging.warning(f\"Invalid class index in '{src_label}': '{original_cls}'. Skipping line.\")\n",
    "                continue\n",
    "            # Map to merged class\n",
    "            if datasets_data[dataset_idx] is None:\n",
    "                logging.warning(f\"No data.yaml found for dataset index {dataset_idx}. Cannot remap classes.\")\n",
    "                remapped_cls = original_cls\n",
    "            else:\n",
    "                cls_name = datasets_data[dataset_idx]['names'][original_cls]\n",
    "                remapped_cls = class_maps[dataset_idx].get(cls_name, original_cls)\n",
    "            remapped_line = f\"{remapped_cls} {x_center} {y_center} {width} {height}\\n\"\n",
    "            remapped_lines.append(remapped_line)\n",
    "\n",
    "        # Write remapped label\n",
    "        with open(dest_label, 'w') as f:\n",
    "            f.writelines(remapped_lines)\n",
    "\n",
    "    logging.info(f\"Copied {len(selected_image_files)} images and labels from '{dataset_path}' to split '{split_type}'\")\n",
    "\n",
    "# Seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Combine datasets with the new split limits\n",
    "for split, num_images in SPLITS.items():\n",
    "    for idx, dataset in enumerate(SOURCE_DATASETS):\n",
    "        select_and_copy(idx, dataset, split, num_images, split)\n",
    "\n",
    "logging.info(\"Dataset combination complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
